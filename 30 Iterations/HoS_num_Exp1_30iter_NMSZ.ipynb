{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VPb1945usGYb",
        "outputId": "78381cf4-faf0-416f-bb84-85eed7b13b31"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pamda\n",
            "  Downloading pamda-2.5.0-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting type-enforced>=1.2.0 (from pamda)\n",
            "  Downloading type_enforced-1.7.0-py3-none-any.whl.metadata (11 kB)\n",
            "Downloading pamda-2.5.0-py3-none-any.whl (18 kB)\n",
            "Downloading type_enforced-1.7.0-py3-none-any.whl (12 kB)\n",
            "Installing collected packages: type-enforced, pamda\n",
            "Successfully installed pamda-2.5.0 type-enforced-1.7.0\n"
          ]
        }
      ],
      "source": [
        "!pip install pamda"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('fema-fl-data-SR_Branch')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rlf2G9KBsRdV",
        "outputId": "b736b33f-2d3e-472e-b3e8-3a93cd002b5a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at fema-fl-data-SR_Branch\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install /content/fema-fl-data-SR_Branch/MyDrive/GitHub/fema-fl-data-SR_Branch/fema_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wI2bWqvzsXhn",
        "outputId": "b40d71df-9892-46c5-ca2b-1923416f878e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing ./fema-fl-data-SR_Branch/MyDrive/GitHub/fema-fl-data-SR_Branch/fema_model\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pamda==0.0.10 (from fema_model==0.1)\n",
            "  Downloading pamda-0.0.10.tar.gz (9.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: fema_model, pamda\n",
            "  Building wheel for fema_model (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fema_model: filename=fema_model-0.1-py3-none-any.whl size=11298 sha256=0abd05d82b9fe20c396a5633855b15b31505e4d944208c5ebdf9d7bbc4544bd7\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-nntwcmo0/wheels/e3/fa/91/be2874dba7a6cd1488352befd13bfec88293e3c87af703ad73\n",
            "  Building wheel for pamda (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pamda: filename=pamda-0.0.10-py3-none-any.whl size=10791 sha256=5e6bd873be22b34439f152644c951088422d438fe29e1af68c99d4edc2d14058\n",
            "  Stored in directory: /root/.cache/pip/wheels/5b/5d/e2/c7497121708bb3d7bab3de1914561fb78b09331b697fed59cc\n",
            "Successfully built fema_model pamda\n",
            "Installing collected packages: pamda, fema_model\n",
            "  Attempting uninstall: pamda\n",
            "    Found existing installation: pamda 2.5.0\n",
            "    Uninstalling pamda-2.5.0:\n",
            "      Successfully uninstalled pamda-2.5.0\n",
            "Successfully installed fema_model-0.1 pamda-0.0.10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/content/fema-fl-data-SR_Branch/MyDrive/GitHub/fema-fl-data-SR_Branch')\n",
        "import sys\n",
        "sys.path.append('/content/fema-fl-data-SR_Branch/MyDrive/GitHub/fema-fl-data-Dependency_Files')\n",
        "import sys\n",
        "sys.path.append('/content/fema-fl-data-SR_Branch/MyDrive/GitHub/fema-fl-data-main')"
      ],
      "metadata": {
        "id": "-5UvlOiVsewk"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pamda import pamda as p\n",
        "from fema_model import Multi_Period_Terminal_System\n",
        "import pandas as pd\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "import requests\n",
        "import json\n",
        "from statsmodels.stats.weightstats import DescrStatsW"
      ],
      "metadata": {
        "id": "irJIXMbGskB3"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "geo_areas = p.read_json('./geo_areas.json')"
      ],
      "metadata": {
        "id": "RTcd6IFyspPx"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Numeric experiments for single sample terminal with different structure parameters\n",
        "# Hours of Service interventions\n",
        "\n",
        "# Fixed parameters\n",
        "\n",
        "# Number of gates\n",
        "n_g = [1,2,3]\n",
        "# Number of bays\n",
        "n_b = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15]\n",
        "# Station distances (miles)\n",
        "d = [25,50,100,150,200,300]\n",
        "# Number of stations\n",
        "S = 250\n",
        "# Bay queue space\n",
        "b_q = 3\n",
        "\n",
        "# Time to empty fuel at station (mins)\n",
        "r_s = 60\n",
        "# Bounds of time to empty fuel at station (mins)\n",
        "r_s_bound = 10\n",
        "# Truck start time max (hrs)\n",
        "a = 6\n",
        "# Truck capacity (gallons)\n",
        "c = 9000\n",
        "# Truck stopping criteria (hr)\n",
        "tau = 0.5\n",
        "\n",
        "# Flexible parameters\n",
        "\n",
        "# Gate check-in time (mins)\n",
        "r_g = 7\n",
        "# Bounds multiplier of gate check-in time (mins)\n",
        "r_g_bound = 0.1\n",
        "# Bay filling time (mins)\n",
        "r_b = 35\n",
        "# Bounds multiplier of bay filling time (mins)\n",
        "r_b_bound = 0.1\n",
        "# Truck speed (mph)\n",
        "v = 45\n",
        "# Bounds multiplier of truck speed (mph)\n",
        "v_bound = 0.1\n",
        "# Hours of service (hrs)\n",
        "h = [14,15,16,17,18,24]\n",
        "# Fleet size (trucks)\n",
        "f = 50\n",
        "\n",
        "# Iterations\n",
        "itrn = 30\n",
        "\n",
        "# Final outputs for all experiments\n",
        "ops_df = pd.DataFrame(columns = ['Iteration', 'Gates', 'Bays', 'Station_Dist', 'Truck_HoS', \\\n",
        "                                 'Flow', 'Trips_Per_Truck', 'Gate_Queue_Wait', 'Driving_Time'])\n",
        "\n",
        "# Input kwargs\n",
        "inputs = {\n",
        "    'carry_over_demand_multiplier':0,\n",
        "    'default_kwargs':{\n",
        "        'demand_situation':'dem_scen_1',\n",
        "        'demand_multiplier':1,\n",
        "        'truck_multiplier':1,\n",
        "        'station_algorithm':'max',\n",
        "        'truck_kwargs':{\n",
        "            'size':c,\n",
        "            'speed':v,\n",
        "            'speed_sigma':v*v_bound,\n",
        "            'empty_rate':r_s,\n",
        "            'empty_rate_sigma':r_s_bound,\n",
        "            'open_time_min':0,\n",
        "            'open_time_max':a,\n",
        "            # 'close_time_after_open':14,\n",
        "            'close_early_delta':tau\n",
        "        },\n",
        "        'station_kwargs':{\n",
        "            'open_time':0,\n",
        "            'close_time':24,\n",
        "        },\n",
        "        'terminal_kwargs':{\n",
        "            'gate_kwargs':{\n",
        "                'gate_rate':r_g,\n",
        "                'gate_rate_sigma':r_g*r_g_bound,\n",
        "                'open_time':0,\n",
        "                'close_time':24,\n",
        "                'extra_gates':0,\n",
        "                'max_gate_queue':None, #Infinite\n",
        "                'share_gate_queue_bool':True\n",
        "            },\n",
        "            'bay_kwargs':{\n",
        "                'open_time':0,\n",
        "                'close_time':24,\n",
        "                'fill_rate':r_b,\n",
        "                'fill_rate_sigma':r_b*r_b_bound,\n",
        "                'extra_bays':0,\n",
        "                'max_bay_queue':b_q,\n",
        "                'share_bay_queue_bool':True\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "# Create terminal system dictionary\n",
        "terminal_system_data = {}\n",
        "terminal_system_data['group1'] = {}\n",
        "terminal_system_data['group1']['trucks_available'] = f\n",
        "terminal_system_data['group1']['terminals'] = {}\n",
        "terminal_system_data['group1']['terminals']['terminal1'] = {}\n",
        "terminal_system_data['group1']['terminals']['terminal1']['fuel_types'] = 'a'\n",
        "\n",
        "# Index of ops_df\n",
        "q = 0\n",
        "\n",
        "for i in tqdm(range(len(n_g))):\n",
        "    terminal_system_data['group1']['terminals']['terminal1']['num_gates'] = n_g[i]\n",
        "    for j in tqdm(range(len(n_b))):\n",
        "        terminal_system_data['group1']['terminals']['terminal1']['num_bays'] = n_b[j]\n",
        "        for k in range(len(d)):\n",
        "            for l in range(itrn):\n",
        "                # Create stations list\n",
        "                terminal_system_data['group1']['stations'] = {}\n",
        "                for m in range(S):\n",
        "                    station_name = 's'+str(m)\n",
        "                    terminal_system_data['group1']['stations'][station_name] = {}\n",
        "                    terminal_system_data['group1']['stations'][station_name]['travel_distance'] = round(random.uniform(0.01,d[k]),3)\n",
        "                    terminal_system_data['group1']['stations'][station_name]['geo_code'] = '1'\n",
        "                    terminal_system_data['group1']['stations'][station_name]['demand_scenarios'] = {}\n",
        "                    terminal_system_data['group1']['stations'][station_name]['demand_scenarios']['dem_scen_1'] = {}\n",
        "                    terminal_system_data['group1']['stations'][station_name]['demand_scenarios']['dem_scen_1']['demand'] = c\n",
        "                    terminal_system_data['group1']['stations'][station_name]['demand_scenarios']['dem_scen_1']['fuel_types'] = 'a'\n",
        "                for n in range(len(h)):\n",
        "                    inputs['default_kwargs']['truck_kwargs']['close_time_after_open'] = h[n]\n",
        "                    periods = [inputs]\n",
        "                    model = Multi_Period_Terminal_System(\n",
        "                            terminal_system_data = terminal_system_data,\n",
        "                            geo_areas = geo_areas,\n",
        "                            periods = periods\n",
        "                            )\n",
        "                    output = model.serialize(minify = True)\n",
        "                    ops_df.loc[q,'Iteration'] = l\n",
        "                    ops_df.loc[q,'Gates'] = n_g[i]\n",
        "                    ops_df.loc[q,'Bays'] = n_b[j]\n",
        "                    ops_df.loc[q,'Station_Dist'] = d[k]\n",
        "                    ops_df.loc[q,'Truck_HoS'] = h[n]\n",
        "                    ops_df.loc[q,'Flow'] = round((output['0']['statistics']['sum_met_total_demand']),3)\n",
        "                    ops_df.loc[q,'Trips_Per_Truck'] = round((output['0']['statistics']['truck_avg_deliveries_made']),3)\n",
        "                    ops_df.loc[q,'Gate_Queue_Wait'] = round((output['0']['statistics']['trip_avg_in_gate_queue']),3)\n",
        "                    ops_df.loc[q,'Driving_Time'] = round((output['0']['statistics']['truck_avg_to_station'] + output['0']['statistics']['truck_avg_to_terminal_group']),3)\n",
        "                    q = q+1\n",
        "\n",
        "ops_df['Gate_Time'] = r_g\n",
        "ops_df['Bay_Time'] = r_b\n",
        "ops_df['Truck_Speed'] = v\n",
        "ops_df['Fleet'] = f\n",
        "\n",
        "ops_df.to_csv('2024-11-13_HoS_Num_Exp_30iter_Results.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xzdixvk7ssJy",
        "outputId": "c34ce129-a3d0-40d5-c11c-02580cd39d1d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/3 [00:00<?, ?it/s]\n",
            "  0%|          | 0/15 [00:00<?, ?it/s]\u001b[A\n",
            "  7%|▋         | 1/15 [01:25<20:00, 85.74s/it]\u001b[A\n",
            " 13%|█▎        | 2/15 [02:57<19:21, 89.31s/it]\u001b[A\n",
            " 20%|██        | 3/15 [04:41<19:09, 95.82s/it]\u001b[A\n",
            " 27%|██▋       | 4/15 [06:37<19:04, 104.02s/it]\u001b[A\n",
            " 33%|███▎      | 5/15 [08:46<18:48, 112.88s/it]\u001b[A\n",
            " 40%|████      | 6/15 [10:59<17:56, 119.65s/it]\u001b[A\n",
            " 47%|████▋     | 7/15 [13:12<16:33, 124.14s/it]\u001b[A\n",
            " 53%|█████▎    | 8/15 [15:29<14:57, 128.18s/it]\u001b[A\n",
            " 60%|██████    | 9/15 [17:45<13:03, 130.67s/it]\u001b[A\n",
            " 67%|██████▋   | 10/15 [20:03<11:05, 133.03s/it]\u001b[A\n",
            " 73%|███████▎  | 11/15 [22:21<08:57, 134.34s/it]\u001b[A\n",
            " 80%|████████  | 12/15 [24:40<06:47, 135.91s/it]\u001b[A\n",
            " 87%|████████▋ | 13/15 [26:59<04:33, 136.84s/it]\u001b[A\n",
            " 93%|█████████▎| 14/15 [29:20<02:18, 138.06s/it]\u001b[A\n",
            "100%|██████████| 15/15 [31:41<00:00, 126.79s/it]\n",
            " 33%|███▎      | 1/3 [31:41<1:03:23, 1901.92s/it]\n",
            "  0%|          | 0/15 [00:00<?, ?it/s]\u001b[A\n",
            "  7%|▋         | 1/15 [01:32<21:33, 92.38s/it]\u001b[A\n",
            " 13%|█▎        | 2/15 [03:19<21:55, 101.20s/it]\u001b[A\n",
            " 20%|██        | 3/15 [05:21<22:05, 110.44s/it]\u001b[A\n",
            " 27%|██▋       | 4/15 [07:33<21:51, 119.23s/it]\u001b[A\n",
            " 33%|███▎      | 5/15 [09:58<21:24, 128.46s/it]\u001b[A\n",
            " 40%|████      | 6/15 [12:32<20:32, 136.90s/it]\u001b[A\n",
            " 47%|████▋     | 7/15 [15:13<19:18, 144.87s/it]\u001b[A\n",
            " 53%|█████▎    | 8/15 [18:03<17:49, 152.81s/it]\u001b[A\n",
            " 60%|██████    | 9/15 [20:58<15:58, 159.74s/it]\u001b[A\n",
            " 67%|██████▋   | 10/15 [23:59<13:51, 166.31s/it]\u001b[A\n",
            " 73%|███████▎  | 11/15 [27:03<11:26, 171.69s/it]\u001b[A\n",
            " 80%|████████  | 12/15 [30:07<08:46, 175.55s/it]\u001b[A\n",
            " 87%|████████▋ | 13/15 [33:13<05:57, 178.66s/it]\u001b[A\n",
            " 93%|█████████▎| 14/15 [36:20<03:01, 181.13s/it]\u001b[A\n",
            "100%|██████████| 15/15 [39:28<00:00, 157.87s/it]\n",
            " 67%|██████▋   | 2/3 [1:11:10<36:16, 2176.16s/it]\n",
            "  0%|          | 0/15 [00:00<?, ?it/s]\u001b[A\n",
            "  7%|▋         | 1/15 [01:47<25:10, 107.90s/it]\u001b[A\n",
            " 13%|█▎        | 2/15 [03:48<24:57, 115.22s/it]\u001b[A\n",
            " 20%|██        | 3/15 [06:05<25:03, 125.26s/it]\u001b[A\n",
            " 27%|██▋       | 4/15 [08:32<24:33, 133.99s/it]\u001b[A\n",
            " 33%|███▎      | 5/15 [11:11<23:48, 142.90s/it]\u001b[A\n",
            " 40%|████      | 6/15 [13:57<22:37, 150.85s/it]\u001b[A\n",
            " 47%|████▋     | 7/15 [16:52<21:09, 158.72s/it]\u001b[A\n",
            " 53%|█████▎    | 8/15 [19:52<19:18, 165.47s/it]\u001b[A\n",
            " 60%|██████    | 9/15 [22:59<17:13, 172.28s/it]\u001b[A\n",
            " 67%|██████▋   | 10/15 [26:13<14:53, 178.74s/it]\u001b[A\n",
            " 73%|███████▎  | 11/15 [29:26<12:13, 183.31s/it]\u001b[A\n",
            " 80%|████████  | 12/15 [32:45<09:24, 188.03s/it]\u001b[A\n",
            " 87%|████████▋ | 13/15 [36:06<06:23, 191.91s/it]\u001b[A\n",
            " 93%|█████████▎| 14/15 [39:28<03:14, 194.89s/it]\u001b[A\n",
            "100%|██████████| 15/15 [42:51<00:00, 171.41s/it]\n",
            "100%|██████████| 3/3 [1:54:01<00:00, 2280.42s/it]\n"
          ]
        }
      ]
    }
  ]
}