{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VPb1945usGYb",
        "outputId": "e0565291-2c16-4600-e246-6bf2ee738583"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pamda\n",
            "  Downloading pamda-2.5.0-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting type-enforced>=1.2.0 (from pamda)\n",
            "  Downloading type_enforced-1.7.0-py3-none-any.whl.metadata (11 kB)\n",
            "Downloading pamda-2.5.0-py3-none-any.whl (18 kB)\n",
            "Downloading type_enforced-1.7.0-py3-none-any.whl (12 kB)\n",
            "Installing collected packages: type-enforced, pamda\n",
            "Successfully installed pamda-2.5.0 type-enforced-1.7.0\n"
          ]
        }
      ],
      "source": [
        "!pip install pamda"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('fema-fl-data-SR_Branch')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rlf2G9KBsRdV",
        "outputId": "56230ccc-2851-45fc-96c1-afc3df14c512"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at fema-fl-data-SR_Branch\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install /content/fema-fl-data-SR_Branch/MyDrive/GitHub/fema-fl-data-SR_Branch/fema_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wI2bWqvzsXhn",
        "outputId": "95d8dcc7-570a-4417-f332-76b8b242cc55"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing ./fema-fl-data-SR_Branch/MyDrive/GitHub/fema-fl-data-SR_Branch/fema_model\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pamda==0.0.10 (from fema_model==0.1)\n",
            "  Downloading pamda-0.0.10.tar.gz (9.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: fema_model, pamda\n",
            "  Building wheel for fema_model (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fema_model: filename=fema_model-0.1-py3-none-any.whl size=11298 sha256=10bb820fa3c15069fb5f7a63a0e90dbf37da1d8d9bde4d3b001f74e986f560e7\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-b2sfdysw/wheels/e3/fa/91/be2874dba7a6cd1488352befd13bfec88293e3c87af703ad73\n",
            "  Building wheel for pamda (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pamda: filename=pamda-0.0.10-py3-none-any.whl size=10791 sha256=517a045f994e9d7cb2d3f3346c3d5acaea1f1e81e5a72f68ec18d38cbeb2d738\n",
            "  Stored in directory: /root/.cache/pip/wheels/5b/5d/e2/c7497121708bb3d7bab3de1914561fb78b09331b697fed59cc\n",
            "Successfully built fema_model pamda\n",
            "Installing collected packages: pamda, fema_model\n",
            "  Attempting uninstall: pamda\n",
            "    Found existing installation: pamda 2.5.0\n",
            "    Uninstalling pamda-2.5.0:\n",
            "      Successfully uninstalled pamda-2.5.0\n",
            "Successfully installed fema_model-0.1 pamda-0.0.10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/content/fema-fl-data-SR_Branch/MyDrive/GitHub/fema-fl-data-SR_Branch')\n",
        "import sys\n",
        "sys.path.append('/content/fema-fl-data-SR_Branch/MyDrive/GitHub/fema-fl-data-Dependency_Files')\n",
        "import sys\n",
        "sys.path.append('/content/fema-fl-data-SR_Branch/MyDrive/GitHub/fema-fl-data-main')"
      ],
      "metadata": {
        "id": "-5UvlOiVsewk"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pamda import pamda as p\n",
        "from fema_model import Multi_Period_Terminal_System\n",
        "import pandas as pd\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "import requests\n",
        "import json\n",
        "from statsmodels.stats.weightstats import DescrStatsW"
      ],
      "metadata": {
        "id": "irJIXMbGskB3"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# first drop the \"geo_areas.json\" to the files\n",
        "geo_areas = p.read_json('./geo_areas.json')"
      ],
      "metadata": {
        "id": "RTcd6IFyspPx"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Numeric experiments for single sample terminal with different structure parameters\n",
        "# Bay interventions\n",
        "\n",
        "# Fixed parameters\n",
        "\n",
        "# Number of gates\n",
        "n_g = [1,2,3]\n",
        "# Number of bays\n",
        "n_b = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15]\n",
        "# Station distances (miles)\n",
        "d = [25,50,100,150,200,300]\n",
        "# Number of stations\n",
        "S = 325\n",
        "# Bay queue space\n",
        "b_q = 3\n",
        "\n",
        "# Time to empty fuel at station (mins)\n",
        "r_s = 60\n",
        "# Bounds of time to empty fuel at station (mins)\n",
        "r_s_bound = 10\n",
        "# Truck start time max (hrs)\n",
        "a = 6\n",
        "# Truck capacity (gallons)\n",
        "c = 9000\n",
        "# Truck stopping criteria (hr)\n",
        "tau = 0.5\n",
        "\n",
        "# Flexible parameters\n",
        "\n",
        "# Gate check-in time (mins)\n",
        "r_g = 7\n",
        "# Bounds multiplier of gate check-in time (mins)\n",
        "r_g_bound = 0.1\n",
        "# Bay filling time (mins)\n",
        "r_b = [15,17.5,20,22.5,25,27.5,30,32.5,35,37.5,40,42.5,45]\n",
        "# Bounds multiplier of bay filling time (mins)\n",
        "r_b_bound = 0.1\n",
        "# Truck speed (mph)\n",
        "v = 45\n",
        "# Bounds multiplier of truck speed (mph)\n",
        "v_bound = 0.1\n",
        "# Hours of service (hrs)\n",
        "h = 14\n",
        "# Fleet size (trucks)\n",
        "f = 50\n",
        "\n",
        "# Iterations\n",
        "itrn = 30\n",
        "\n",
        "# Final outputs for all experiments\n",
        "ops_df = pd.DataFrame(columns = ['Iteration', 'Gates', 'Bays', 'Station_Dist', 'Bay_Time', \\\n",
        "                                 'Flow', 'Trips_Per_Truck', 'Gate_Queue_Wait', 'Driving_Time'])\n",
        "\n",
        "# Input kwargs\n",
        "inputs = {\n",
        "    'carry_over_demand_multiplier':0,\n",
        "    'default_kwargs':{\n",
        "        'demand_situation':'dem_scen_1',\n",
        "        'demand_multiplier':1,\n",
        "        'truck_multiplier':1,\n",
        "        'station_algorithm':'max',\n",
        "        'truck_kwargs':{\n",
        "            'size':c,\n",
        "            'speed':v,\n",
        "            'speed_sigma':v*v_bound,\n",
        "            'empty_rate':r_s,\n",
        "            'empty_rate_sigma':r_s_bound,\n",
        "            'open_time_min':0,\n",
        "            'open_time_max':a,\n",
        "            'close_time_after_open':h,\n",
        "            'close_early_delta':tau\n",
        "        },\n",
        "        'station_kwargs':{\n",
        "            'open_time':0,\n",
        "            'close_time':24,\n",
        "        },\n",
        "        'terminal_kwargs':{\n",
        "            'gate_kwargs':{\n",
        "                'gate_rate':r_g,\n",
        "                'gate_rate_sigma':r_g*r_g_bound,\n",
        "                'open_time':0,\n",
        "                'close_time':24,\n",
        "                'extra_gates':0,\n",
        "                'max_gate_queue':None, #Infinite\n",
        "                'share_gate_queue_bool':True\n",
        "            },\n",
        "            'bay_kwargs':{\n",
        "                'open_time':0,\n",
        "                'close_time':24,\n",
        "                # 'fill_rate':35,\n",
        "                # 'fill_rate_sigma':35*r_b_bound,\n",
        "                'extra_bays':0,\n",
        "                'max_bay_queue':b_q,\n",
        "                'share_bay_queue_bool':True\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "# Create terminal system dictionary\n",
        "terminal_system_data = {}\n",
        "terminal_system_data['group1'] = {}\n",
        "terminal_system_data['group1']['trucks_available'] = f\n",
        "terminal_system_data['group1']['terminals'] = {}\n",
        "terminal_system_data['group1']['terminals']['terminal1'] = {}\n",
        "terminal_system_data['group1']['terminals']['terminal1']['fuel_types'] = 'a'\n",
        "\n",
        "# Index of ops_df\n",
        "q = 0\n",
        "\n",
        "for i in tqdm(range(len(n_g))):\n",
        "    terminal_system_data['group1']['terminals']['terminal1']['num_gates'] = n_g[i]\n",
        "    for j in tqdm(range(len(n_b))):\n",
        "        terminal_system_data['group1']['terminals']['terminal1']['num_bays'] = n_b[j]\n",
        "        for k in range(len(d)):\n",
        "            for l in range(itrn):\n",
        "                # Create stations list\n",
        "                terminal_system_data['group1']['stations'] = {}\n",
        "                for m in range(S):\n",
        "                    station_name = 's'+str(m)\n",
        "                    terminal_system_data['group1']['stations'][station_name] = {}\n",
        "                    terminal_system_data['group1']['stations'][station_name]['travel_distance'] = round(random.uniform(0.01,d[k]),3)\n",
        "                    terminal_system_data['group1']['stations'][station_name]['geo_code'] = '1'\n",
        "                    terminal_system_data['group1']['stations'][station_name]['demand_scenarios'] = {}\n",
        "                    terminal_system_data['group1']['stations'][station_name]['demand_scenarios']['dem_scen_1'] = {}\n",
        "                    terminal_system_data['group1']['stations'][station_name]['demand_scenarios']['dem_scen_1']['demand'] = c\n",
        "                    terminal_system_data['group1']['stations'][station_name]['demand_scenarios']['dem_scen_1']['fuel_types'] = 'a'\n",
        "                for n in range(len(r_b)):\n",
        "                    inputs['default_kwargs']['terminal_kwargs']['bay_kwargs']['fill_rate'] = r_b[n]\n",
        "                    inputs['default_kwargs']['terminal_kwargs']['bay_kwargs']['fill_rate_sigma'] = r_b[n]*r_b_bound\n",
        "                    periods = [inputs]\n",
        "                    model = Multi_Period_Terminal_System(\n",
        "                            terminal_system_data = terminal_system_data,\n",
        "                            geo_areas = geo_areas,\n",
        "                            periods = periods\n",
        "                            )\n",
        "                    output = model.serialize(minify = True)\n",
        "                    ops_df.loc[q,'Iteration'] = l\n",
        "                    ops_df.loc[q,'Gates'] = n_g[i]\n",
        "                    ops_df.loc[q,'Bays'] = n_b[j]\n",
        "                    ops_df.loc[q,'Station_Dist'] = d[k]\n",
        "                    ops_df.loc[q,'Bay_Time'] = r_b[n]\n",
        "                    ops_df.loc[q,'Flow'] = round((output['0']['statistics']['sum_met_total_demand']),3)\n",
        "                    ops_df.loc[q,'Trips_Per_Truck'] = round((output['0']['statistics']['truck_avg_deliveries_made']),3)\n",
        "                    ops_df.loc[q,'Gate_Queue_Wait'] = round((output['0']['statistics']['trip_avg_in_gate_queue']),3)\n",
        "                    ops_df.loc[q,'Driving_Time'] = round((output['0']['statistics']['truck_avg_to_station'] + output['0']['statistics']['truck_avg_to_terminal_group']),3)\n",
        "                    q = q+1\n",
        "\n",
        "ops_df['Gate_Time'] = r_g\n",
        "ops_df['Truck_Speed'] = v\n",
        "ops_df['Truck_HoS'] = h\n",
        "ops_df['Fleet'] = f\n",
        "\n",
        "ops_df.to_csv('2024-11-13_Bay_Num_Exp1_30iter_Results.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xzdixvk7ssJy",
        "outputId": "1fdf0664-649b-413b-ac6a-31e5ae258b60"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/3 [00:00<?, ?it/s]\n",
            "  0%|          | 0/15 [00:00<?, ?it/s]\u001b[A\n",
            "  7%|▋         | 1/15 [03:31<49:25, 211.84s/it]\u001b[A\n",
            " 13%|█▎        | 2/15 [07:38<50:23, 232.60s/it]\u001b[A\n",
            " 20%|██        | 3/15 [12:14<50:28, 252.36s/it]\u001b[A\n",
            " 27%|██▋       | 4/15 [17:23<50:19, 274.48s/it]\u001b[A\n",
            " 33%|███▎      | 5/15 [22:40<48:18, 289.84s/it]\u001b[A\n",
            " 40%|████      | 6/15 [28:06<45:19, 302.19s/it]\u001b[A\n",
            " 47%|████▋     | 7/15 [33:35<41:27, 310.97s/it]\u001b[A\n",
            " 53%|█████▎    | 8/15 [39:10<37:11, 318.75s/it]\u001b[A\n",
            " 60%|██████    | 9/15 [44:48<32:28, 324.74s/it]\u001b[A\n",
            " 67%|██████▋   | 10/15 [50:29<27:27, 329.54s/it]\u001b[A\n",
            " 73%|███████▎  | 11/15 [56:09<22:11, 332.81s/it]\u001b[A\n",
            " 80%|████████  | 12/15 [1:01:52<16:48, 336.05s/it]\u001b[A\n",
            " 87%|████████▋ | 13/15 [1:07:45<11:21, 340.96s/it]\u001b[A\n",
            " 93%|█████████▎| 14/15 [1:13:37<05:44, 344.56s/it]\u001b[A\n",
            "100%|██████████| 15/15 [1:19:32<00:00, 318.15s/it]\n",
            " 33%|███▎      | 1/3 [1:19:32<2:39:04, 4772.26s/it]\n",
            "  0%|          | 0/15 [00:00<?, ?it/s]\u001b[A\n",
            "  7%|▋         | 1/15 [04:25<1:01:55, 265.39s/it]\u001b[A\n",
            " 13%|█▎        | 2/15 [09:25<1:01:59, 286.08s/it]\u001b[A\n",
            " 20%|██        | 3/15 [14:59<1:01:34, 307.90s/it]\u001b[A\n",
            " 27%|██▋       | 4/15 [20:59<1:00:12, 328.36s/it]\u001b[A\n",
            " 33%|███▎      | 5/15 [27:25<58:12, 349.30s/it]  \u001b[A\n",
            " 40%|████      | 6/15 [34:07<55:04, 367.12s/it]\u001b[A\n",
            " 47%|████▋     | 7/15 [41:03<51:04, 383.08s/it]\u001b[A\n",
            " 53%|█████▎    | 8/15 [48:10<46:18, 396.92s/it]\u001b[A\n",
            " 60%|██████    | 9/15 [55:24<40:51, 408.64s/it]\u001b[A\n",
            " 67%|██████▋   | 10/15 [1:02:47<34:55, 419.11s/it]\u001b[A\n",
            " 73%|███████▎  | 11/15 [1:10:16<28:33, 428.38s/it]\u001b[A\n",
            " 80%|████████  | 12/15 [1:17:56<21:53, 437.94s/it]\u001b[A\n",
            " 87%|████████▋ | 13/15 [1:25:37<14:49, 444.92s/it]\u001b[A\n",
            " 93%|█████████▎| 14/15 [1:33:23<07:31, 451.47s/it]\u001b[A\n",
            "100%|██████████| 15/15 [1:41:11<00:00, 404.79s/it]\n",
            " 67%|██████▋   | 2/3 [3:00:44<1:32:16, 5536.70s/it]\n",
            "  0%|          | 0/15 [00:00<?, ?it/s]\u001b[A\n",
            "  7%|▋         | 1/15 [05:09<1:12:17, 309.79s/it]\u001b[A\n",
            " 13%|█▎        | 2/15 [10:56<1:11:52, 331.74s/it]\u001b[A\n",
            " 20%|██        | 3/15 [17:14<1:10:34, 352.87s/it]\u001b[A\n",
            " 27%|██▋       | 4/15 [23:59<1:08:27, 373.44s/it]\u001b[A\n",
            " 33%|███▎      | 5/15 [31:09<1:05:37, 393.71s/it]\u001b[A\n",
            " 40%|████      | 6/15 [38:36<1:01:46, 411.88s/it]\u001b[A\n",
            " 47%|████▋     | 7/15 [46:13<56:53, 426.71s/it]  \u001b[A\n",
            " 53%|█████▎    | 8/15 [54:03<51:23, 440.51s/it]\u001b[A\n",
            " 60%|██████    | 9/15 [1:02:07<45:23, 453.96s/it]\u001b[A\n",
            " 67%|██████▋   | 10/15 [1:10:15<38:41, 464.31s/it]\u001b[A\n",
            " 73%|███████▎  | 11/15 [1:18:29<31:34, 473.51s/it]\u001b[A\n",
            " 80%|████████  | 12/15 [1:26:51<24:06, 482.07s/it]\u001b[A\n",
            " 87%|████████▋ | 13/15 [1:35:19<16:19, 489.94s/it]\u001b[A\n",
            " 93%|█████████▎| 14/15 [1:43:56<08:18, 498.26s/it]\u001b[A\n",
            "100%|██████████| 15/15 [1:52:42<00:00, 450.84s/it]\n",
            "100%|██████████| 3/3 [4:53:26<00:00, 5868.90s/it]\n"
          ]
        }
      ]
    }
  ]
}