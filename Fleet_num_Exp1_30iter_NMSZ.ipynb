{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VPb1945usGYb",
        "outputId": "32644680-b6b4-40f8-89bc-095fdb89abb8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pamda\n",
            "  Downloading pamda-2.5.0-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting type-enforced>=1.2.0 (from pamda)\n",
            "  Downloading type_enforced-1.7.0-py3-none-any.whl.metadata (11 kB)\n",
            "Downloading pamda-2.5.0-py3-none-any.whl (18 kB)\n",
            "Downloading type_enforced-1.7.0-py3-none-any.whl (12 kB)\n",
            "Installing collected packages: type-enforced, pamda\n",
            "Successfully installed pamda-2.5.0 type-enforced-1.7.0\n"
          ]
        }
      ],
      "source": [
        "!pip install pamda"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('fema-fl-data-SR_Branch')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rlf2G9KBsRdV",
        "outputId": "c892e94f-e329-4e94-ee15-b32e6c3881e0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at fema-fl-data-SR_Branch\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install /content/fema-fl-data-SR_Branch/MyDrive/GitHub/fema-fl-data-SR_Branch/fema_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wI2bWqvzsXhn",
        "outputId": "30ad9d70-c50b-43a6-855e-192ee1606e8e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing ./fema-fl-data-SR_Branch/MyDrive/GitHub/fema-fl-data-SR_Branch/fema_model\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pamda==0.0.10 (from fema_model==0.1)\n",
            "  Downloading pamda-0.0.10.tar.gz (9.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: fema_model, pamda\n",
            "  Building wheel for fema_model (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fema_model: filename=fema_model-0.1-py3-none-any.whl size=11298 sha256=ad7cd00aef32b9f6eed7297bd428a952f2f6011d30d4176a6d77b8d5d00e702c\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-93q2y8c0/wheels/e3/fa/91/be2874dba7a6cd1488352befd13bfec88293e3c87af703ad73\n",
            "  Building wheel for pamda (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pamda: filename=pamda-0.0.10-py3-none-any.whl size=10791 sha256=6fc48047559b3e402b454d8570ad777e07a5c6d90951b92efb78034984a53f19\n",
            "  Stored in directory: /root/.cache/pip/wheels/5b/5d/e2/c7497121708bb3d7bab3de1914561fb78b09331b697fed59cc\n",
            "Successfully built fema_model pamda\n",
            "Installing collected packages: pamda, fema_model\n",
            "  Attempting uninstall: pamda\n",
            "    Found existing installation: pamda 2.5.0\n",
            "    Uninstalling pamda-2.5.0:\n",
            "      Successfully uninstalled pamda-2.5.0\n",
            "Successfully installed fema_model-0.1 pamda-0.0.10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/content/fema-fl-data-SR_Branch/MyDrive/GitHub/fema-fl-data-SR_Branch')\n",
        "import sys\n",
        "sys.path.append('/content/fema-fl-data-SR_Branch/MyDrive/GitHub/fema-fl-data-Dependency_Files')\n",
        "import sys\n",
        "sys.path.append('/content/fema-fl-data-SR_Branch/MyDrive/GitHub/fema-fl-data-main')"
      ],
      "metadata": {
        "id": "-5UvlOiVsewk"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pamda import pamda as p\n",
        "from fema_model import Multi_Period_Terminal_System\n",
        "import pandas as pd\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "import requests\n",
        "import json\n",
        "from statsmodels.stats.weightstats import DescrStatsW"
      ],
      "metadata": {
        "id": "irJIXMbGskB3"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# first drop the \"geo_areas.json\" to the files\n",
        "geo_areas = p.read_json('./geo_areas.json')"
      ],
      "metadata": {
        "id": "RTcd6IFyspPx"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Numeric experiments for single sample terminal with different structure parameters\n",
        "# Fleet interventions\n",
        "\n",
        "# Fixed parameters\n",
        "\n",
        "# Number of gates\n",
        "n_g = [1,2,3]\n",
        "# Number of bays\n",
        "n_b = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15]\n",
        "# Station distances (miles)\n",
        "d = [25,50,100,150,200,300]\n",
        "# Number of stations\n",
        "S = 250\n",
        "# Bay queue space\n",
        "b_q = 3\n",
        "\n",
        "# Time to empty fuel at station (mins)\n",
        "r_s = 60\n",
        "# Bounds of time to empty fuel at station (mins)\n",
        "r_s_bound = 10\n",
        "# Truck start time max (hrs)\n",
        "a = 6\n",
        "# Truck capacity (gallons)\n",
        "c = 9000\n",
        "# Truck stopping criteria (hr)\n",
        "tau = 0.5\n",
        "\n",
        "# Flexible parameters\n",
        "\n",
        "# Gate check-in time (mins)\n",
        "r_g = 7\n",
        "# Bounds multiplier of gate check-in time (mins)\n",
        "r_g_bound = 0.1\n",
        "# Bay filling time (mins)\n",
        "r_b = 35\n",
        "# Bounds multiplier of bay filling time (mins)\n",
        "r_b_bound = 0.1\n",
        "# Truck speed (mph)\n",
        "v = 45\n",
        "# Bounds multiplier  of truck speed (mph)\n",
        "v_bound = 0.1\n",
        "# Hours of service (hrs)\n",
        "h = 14\n",
        "# Fleet size (trucks)\n",
        "f = [10,25,50,75,100,125,150,175,200]\n",
        "\n",
        "# Iterations\n",
        "itrn = 30\n",
        "\n",
        "# Final outputs for all experiments\n",
        "ops_df = pd.DataFrame(columns = ['Iteration', 'Gates', 'Bays', 'Station_Dist', 'Fleet', \\\n",
        "                                 'Flow', 'Trips_Per_Truck', 'Gate_Queue_Wait', 'Driving_Time'])\n",
        "\n",
        "# Input kwargs\n",
        "inputs = {\n",
        "    'carry_over_demand_multiplier':0,\n",
        "    'default_kwargs':{\n",
        "        'demand_situation':'dem_scen_1',\n",
        "        'demand_multiplier':1,\n",
        "        'truck_multiplier':1,\n",
        "        'station_algorithm':'max',\n",
        "        'truck_kwargs':{\n",
        "            'size':c,\n",
        "            'speed':v,\n",
        "            'speed_sigma':v*v_bound,\n",
        "            'empty_rate':r_s,\n",
        "            'empty_rate_sigma':r_s_bound,\n",
        "            'open_time_min':0,\n",
        "            'open_time_max':a,\n",
        "            'close_time_after_open':h,\n",
        "            'close_early_delta':tau\n",
        "        },\n",
        "        'station_kwargs':{\n",
        "            'open_time':0,\n",
        "            'close_time':24,\n",
        "        },\n",
        "        'terminal_kwargs':{\n",
        "            'gate_kwargs':{\n",
        "                'gate_rate':r_g,\n",
        "                'gate_rate_sigma':r_g*r_g_bound,\n",
        "                'open_time':0,\n",
        "                'close_time':24,\n",
        "                'extra_gates':0,\n",
        "                'max_gate_queue':None, #Infinite\n",
        "                'share_gate_queue_bool':True\n",
        "            },\n",
        "            'bay_kwargs':{\n",
        "                'open_time':0,\n",
        "                'close_time':24,\n",
        "                'fill_rate':r_b,\n",
        "                'fill_rate_sigma':r_b*r_b_bound,\n",
        "                'extra_bays':0,\n",
        "                'max_bay_queue':b_q,\n",
        "                'share_bay_queue_bool':True\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "# Create terminal system dictionary\n",
        "terminal_system_data = {}\n",
        "terminal_system_data['group1'] = {}\n",
        "terminal_system_data['group1']['terminals'] = {}\n",
        "terminal_system_data['group1']['terminals']['terminal1'] = {}\n",
        "terminal_system_data['group1']['terminals']['terminal1']['fuel_types'] = 'a'\n",
        "\n",
        "# Index of ops_df\n",
        "q = 0\n",
        "\n",
        "for i in tqdm(range(len(n_g))):\n",
        "    terminal_system_data['group1']['terminals']['terminal1']['num_gates'] = n_g[i]\n",
        "    for j in tqdm(range(len(n_b))):\n",
        "        terminal_system_data['group1']['terminals']['terminal1']['num_bays'] = n_b[j]\n",
        "        for k in range(len(d)):\n",
        "            for l in range(itrn):\n",
        "                # Create stations list\n",
        "                terminal_system_data['group1']['stations'] = {}\n",
        "                for m in range(S):\n",
        "                    station_name = 's'+str(m)\n",
        "                    terminal_system_data['group1']['stations'][station_name] = {}\n",
        "                    terminal_system_data['group1']['stations'][station_name]['travel_distance'] = round(random.uniform(0.01,d[k]),3)\n",
        "                    terminal_system_data['group1']['stations'][station_name]['geo_code'] = '1'\n",
        "                    terminal_system_data['group1']['stations'][station_name]['demand_scenarios'] = {}\n",
        "                    terminal_system_data['group1']['stations'][station_name]['demand_scenarios']['dem_scen_1'] = {}\n",
        "                    terminal_system_data['group1']['stations'][station_name]['demand_scenarios']['dem_scen_1']['demand'] = c\n",
        "                    terminal_system_data['group1']['stations'][station_name]['demand_scenarios']['dem_scen_1']['fuel_types'] = 'a'\n",
        "                for n in range(len(f)):\n",
        "                    terminal_system_data['group1']['trucks_available'] = f[n]\n",
        "                    periods = [inputs]\n",
        "                    model = Multi_Period_Terminal_System(\n",
        "                            terminal_system_data = terminal_system_data,\n",
        "                            geo_areas = geo_areas,\n",
        "                            periods = periods\n",
        "                            )\n",
        "                    output = model.serialize(minify = True)\n",
        "                    ops_df.loc[q,'Iteration'] = l\n",
        "                    ops_df.loc[q,'Gates'] = n_g[i]\n",
        "                    ops_df.loc[q,'Bays'] = n_b[j]\n",
        "                    ops_df.loc[q,'Station_Dist'] = d[k]\n",
        "                    ops_df.loc[q,'Fleet'] = f[n]\n",
        "                    ops_df.loc[q,'Flow'] = round((output['0']['statistics']['sum_met_total_demand']),3)\n",
        "                    ops_df.loc[q,'Trips_Per_Truck'] = round((output['0']['statistics']['truck_avg_deliveries_made']),3)\n",
        "                    ops_df.loc[q,'Gate_Queue_Wait'] = round((output['0']['statistics']['trip_avg_in_gate_queue']),3)\n",
        "                    ops_df.loc[q,'Driving_Time'] = round((output['0']['statistics']['truck_avg_to_station'] + output['0']['statistics']['truck_avg_to_terminal_group']),3)\n",
        "                    q = q+1\n",
        "\n",
        "ops_df['Gate_Time'] = r_g\n",
        "ops_df['Bay_Time'] = r_b\n",
        "ops_df['Truck_Speed'] = v\n",
        "ops_df['Truck_HoS'] = h\n",
        "\n",
        "ops_df.to_csv('2024-11-13_Fleet_Num_Exp_30iter_Results.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JZUm0Q-0MdID",
        "outputId": "ab42fc01-0628-4192-b7d2-2c81aebd2dad"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/3 [00:00<?, ?it/s]\n",
            "  0%|          | 0/15 [00:00<?, ?it/s]\u001b[A\n",
            "  7%|▋         | 1/15 [02:23<33:33, 143.82s/it]\u001b[A\n",
            " 13%|█▎        | 2/15 [05:03<33:10, 153.11s/it]\u001b[A\n",
            " 20%|██        | 3/15 [08:00<32:46, 163.90s/it]\u001b[A\n",
            " 27%|██▋       | 4/15 [11:13<32:10, 175.47s/it]\u001b[A\n",
            " 33%|███▎      | 5/15 [14:45<31:27, 188.77s/it]\u001b[A\n",
            " 40%|████      | 6/15 [18:23<29:49, 198.79s/it]\u001b[A\n",
            " 47%|████▋     | 7/15 [22:05<27:29, 206.22s/it]\u001b[A\n",
            " 53%|█████▎    | 8/15 [25:48<24:40, 211.47s/it]\u001b[A\n",
            " 60%|██████    | 9/15 [29:32<21:33, 215.59s/it]\u001b[A\n",
            " 67%|██████▋   | 10/15 [33:19<18:14, 218.89s/it]\u001b[A\n",
            " 73%|███████▎  | 11/15 [37:05<14:44, 221.04s/it]\u001b[A\n",
            " 80%|████████  | 12/15 [40:51<11:08, 222.75s/it]\u001b[A\n",
            " 87%|████████▋ | 13/15 [44:40<07:28, 224.47s/it]\u001b[A\n",
            " 93%|█████████▎| 14/15 [48:31<03:46, 226.41s/it]\u001b[A\n",
            "100%|██████████| 15/15 [52:25<00:00, 209.72s/it]\n",
            " 33%|███▎      | 1/3 [52:25<1:44:51, 3145.78s/it]\n",
            "  0%|          | 0/15 [00:00<?, ?it/s]\u001b[A\n",
            "  7%|▋         | 1/15 [02:53<40:23, 173.10s/it]\u001b[A\n",
            " 13%|█▎        | 2/15 [06:02<39:36, 182.83s/it]\u001b[A\n",
            " 20%|██        | 3/15 [09:30<38:49, 194.15s/it]\u001b[A\n",
            " 27%|██▋       | 4/15 [13:14<37:43, 205.80s/it]\u001b[A\n",
            " 33%|███▎      | 5/15 [17:15<36:26, 218.66s/it]\u001b[A\n",
            " 40%|████      | 6/15 [21:34<34:49, 232.22s/it]\u001b[A\n",
            " 47%|████▋     | 7/15 [26:08<32:49, 246.13s/it]\u001b[A\n",
            " 53%|█████▎    | 8/15 [31:01<30:26, 260.89s/it]\u001b[A\n",
            " 60%|██████    | 9/15 [36:10<27:36, 276.14s/it]\u001b[A\n",
            " 67%|██████▋   | 10/15 [41:40<24:23, 292.69s/it]\u001b[A\n",
            " 73%|███████▎  | 11/15 [47:28<20:37, 309.43s/it]\u001b[A\n",
            " 80%|████████  | 12/15 [53:13<16:01, 320.52s/it]\u001b[A\n",
            " 87%|████████▋ | 13/15 [59:02<10:57, 328.86s/it]\u001b[A\n",
            " 93%|█████████▎| 14/15 [1:04:52<05:35, 335.53s/it]\u001b[A\n",
            "100%|██████████| 15/15 [1:10:43<00:00, 282.92s/it]\n",
            " 67%|██████▋   | 2/3 [2:03:09<1:03:11, 3791.71s/it]\n",
            "  0%|          | 0/15 [00:00<?, ?it/s]\u001b[A\n",
            "  7%|▋         | 1/15 [03:15<45:30, 195.05s/it]\u001b[A\n",
            " 13%|█▎        | 2/15 [06:48<44:35, 205.82s/it]\u001b[A\n",
            " 20%|██        | 3/15 [10:38<43:22, 216.84s/it]\u001b[A\n",
            " 27%|██▋       | 4/15 [14:47<42:06, 229.67s/it]\u001b[A\n",
            " 33%|███▎      | 5/15 [19:13<40:28, 242.84s/it]\u001b[A\n",
            " 40%|████      | 6/15 [23:57<38:29, 256.59s/it]\u001b[A\n",
            " 47%|████▋     | 7/15 [29:00<36:15, 271.97s/it]\u001b[A\n",
            " 53%|█████▎    | 8/15 [34:21<33:32, 287.45s/it]\u001b[A\n",
            " 60%|██████    | 9/15 [40:02<30:24, 304.16s/it]\u001b[A\n",
            " 67%|██████▋   | 10/15 [46:00<26:43, 320.79s/it]\u001b[A\n",
            " 73%|███████▎  | 11/15 [52:19<22:34, 338.61s/it]\u001b[A\n",
            " 80%|████████  | 12/15 [58:43<17:37, 352.60s/it]\u001b[A\n",
            " 87%|████████▋ | 13/15 [1:05:13<12:07, 363.74s/it]\u001b[A\n",
            " 93%|█████████▎| 14/15 [1:11:48<06:13, 373.19s/it]\u001b[A\n",
            "100%|██████████| 15/15 [1:18:28<00:00, 313.91s/it]\n",
            "100%|██████████| 3/3 [3:21:38<00:00, 4032.77s/it]\n"
          ]
        }
      ]
    }
  ]
}